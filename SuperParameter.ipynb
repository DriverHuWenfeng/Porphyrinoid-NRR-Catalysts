{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f99407-8d9a-4944-87bb-207c0ff8e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from matplotlib import rcParams\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import seaborn as sns  # 引入 seaborn 以利用其色彩方案\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b3a2d-f93a-4c7e-9115-3bc4a12c06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局字体大小等设置\n",
    "global_font_size = 14\n",
    "font_family = 'serif'\n",
    "font_serif = ['Times New Roman']\n",
    "font_weight = 'bold'\n",
    "# 更新matplotlib全局字体参数\n",
    "\n",
    "rcParams.update({\n",
    "    'font.family': font_family,\n",
    "    'font.serif': font_serif,\n",
    "    'font.weight': font_weight,\n",
    "    'font.size': global_font_size,\n",
    "})\n",
    "\n",
    "\n",
    "data = pd.read_csv(r'training_set-411.csv')\n",
    "X = data.iloc[:, 1:-5] \n",
    "y = data.iloc[:,-5:]\n",
    "# X.replace('none', np.nan, inplace=True)\n",
    "symbol_columns = ['TM', 'modifications_ring', 'modifications_chain', 'Conjugate_structure','period','group_id']\n",
    "for column in symbol_columns:\n",
    "    X[column], _ = pd.factorize(X[column])\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# data_filled = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19198ca-7d5a-43a6-a609-0b3886e27d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调节超参数\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def TrainSVM(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1,100 , 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf'],\n",
    "    }\n",
    "\n",
    "        # 初始化回归模型\n",
    "    dt = SVR()\n",
    "    grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring=rmse_scorer)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 打印最佳参数组合和最佳得分\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    #使用最佳组合计算\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_out = best_model.predict(X_train)\n",
    "    \n",
    "    # 计算预测值与真实标签之间的RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_out))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {:.2f}\".format(test_rmse))\n",
    "    print(\"Training RMSE: {:.2f}\".format(train_rmse))\n",
    "    \n",
    "    # 计算R2\n",
    "    # y_pred = best_model.predict(X_test)\n",
    "    # y_out = best_model.predict(X_train)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    print(\"SVR \\n RMSE: \", test_rmse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    # plot\n",
    "    fig, ax1 = plt.subplots()\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.16, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.11, f\"Training RMSE: {train_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"Test RMSE: {test_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1eed7-d8cb-4a9c-9851-b49fdcd413b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调节超参数\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def TrainDeciTree(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "    param_grid = {\n",
    "        'max_depth': [None, 5, 10, 20, 40],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "        # 初始化决策树回归模型\n",
    "    dt = DecisionTreeRegressor()\n",
    "    grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring=rmse_scorer)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 打印最佳参数组合和最佳得分\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    #使用最佳组合计算\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_out = best_model.predict(X_train)\n",
    "    \n",
    "    # 计算预测值与真实标签之间的RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_out))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {:.2f}\".format(test_rmse))\n",
    "    print(\"Training RMSE: {:.2f}\".format(train_rmse))\n",
    "    \n",
    "    # 计算R2\n",
    "    # y_pred = best_model.predict(X_test)\n",
    "    # y_out = best_model.predict(X_train)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    print(\"Decision Tree Regression \\n RMSE: \", test_rmse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    # plot\n",
    "    fig, ax1 = plt.subplots()\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.16, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.11, f\"Training RMSE: {train_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"Test RMSE: {test_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d209748-da9b-42da-9b2a-057f74a6100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 调节超参数\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def TrainRandForest(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [20],\n",
    "        'min_samples_split': [2, 5, 10, 15, 20],\n",
    "        'min_samples_leaf': [1, 2, 4, 10]\n",
    "    }\n",
    "\n",
    "    # 拟合模型\n",
    "    rf = RandomForestRegressor()\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring=rmse_scorer)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 打印最佳参数组合和最佳得分\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    #使用最佳组合计算\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_out = best_model.predict(X_train)\n",
    "\n",
    "    # 计算预测值与真实标签之间的RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_out))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {:.2f}\".format(test_rmse))\n",
    "    print(\"Training RMSE: {:.2f}\".format(train_rmse))\n",
    "    \n",
    "    # 计算R2\n",
    "    # y_pred = best_model.predict(X_test)\n",
    "    # y_out = best_model.predict(X_train)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    print(\"Random Forest Regression \\n RMSE: \", test_rmse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    # plot\n",
    "    fig, ax1 = plt.subplots()\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.16, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.11, f\"Training RMSE: {train_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"Test RMSE: {test_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9e0ae-7ac4-4e45-84a0-cc14e9a6a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调节超参数\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def TrainBoost(X, y):\n",
    "    rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.5]\n",
    "#         'max_depth': [3, 5, 7],\n",
    "#         'min_samples_split': [2, 5, 10],\n",
    "#         'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    gb = GBR()\n",
    "    grid_search = GridSearchCV(estimator=gb, param_grid=param_grid, cv=5, scoring=rmse_scorer)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # 打印最佳参数组合和最佳得分\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    #使用最佳组合计算\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_out = best_model.predict(X_train)\n",
    "\n",
    "    # 计算预测值与真实标签之间的RMSE\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_out))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {:.2f}\".format(test_rmse))\n",
    "    print(\"Training RMSE: {:.2f}\".format(train_rmse))\n",
    "    \n",
    "    # 计算R2\n",
    "    # y_pred = best_model.predict(X_test)\n",
    "    # y_out = best_model.predict(X_train)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    print(\"GBR \\n RMSE: \", test_rmse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    # plot\n",
    "    fig, ax1 = plt.subplots()\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.16, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.11, f\"Training RMSE: {train_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"Test RMSE: {test_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa9f71-05d7-4e29-aabb-599ace13253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=y.columns)\n",
    "result.insert(0, 'Method', ['SVM', 'Linear Regression', 'Decision Tree Regression', 'Random Forest Regression', 'Gradient Boosting Regression', 'Mean MSE'])\n",
    "# for i in range(5):\n",
    "i = 4\n",
    "print(y.columns[i], \"as label\")\n",
    "data1 = pd.concat([X, y.iloc[:,i]], axis=1)\n",
    "# 删除含有缺失标签的样本\n",
    "data_cleaned = data1.dropna(subset=[data1.columns[-1]])\n",
    "\n",
    "# 分离特征和标签\n",
    "X_cleaned = data_cleaned.iloc[:, :-1]  # 取前n-1列为特征\n",
    "y_cleaned = data_cleaned.iloc[:,-1]  # 取最后一列为标签\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0e0df-faff-4223-94d7-5a2e686b3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseSVM = TrainSVM(X_cleaned, y_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb85ec5-6801-452a-9908-f9222da8c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseDeciTree = TrainDeciTree(X_cleaned, y_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954f1bf-7336-4f38-93bb-b673c08eb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseRandForest = TrainRandForest(X_cleaned, y_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645e189-c74b-4ff6-8ed7-52db758bd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseBoost = TrainBoost(X_cleaned, y_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7333b-785a-4de4-9c7a-08ab95e3c681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07907d5f-cfc0-4494-8405-99531a0684cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
