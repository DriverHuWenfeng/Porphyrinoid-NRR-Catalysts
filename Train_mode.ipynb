{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns  # 引入 seaborn 以利用其色彩方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局字体大小等设置\n",
    "global_font_size = 14\n",
    "font_family = 'serif'\n",
    "font_serif = ['Times New Roman']\n",
    "font_weight = 'bold'\n",
    "# 更新matplotlib全局字体参数\n",
    "\n",
    "rcParams.update({\n",
    "    'font.family': font_family,\n",
    "    'font.serif': font_serif,\n",
    "    'font.weight': font_weight,\n",
    "    'font.size': global_font_size,\n",
    "})\n",
    "\n",
    "\n",
    "data = pd.read_csv(r'training_set-411.csv')\n",
    "X = data.iloc[:, 1:-5] \n",
    "y = data.iloc[:,-5:]\n",
    "\n",
    "#标准化特征\n",
    "stdscale = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "# numerical_features = X.select_dtypes(include='number')\n",
    "# scaled_numerical_data = scaler.fit_transform(numerical_features)\n",
    "# X = scaled_numerical_data\n",
    "# X.replace('none', np.nan, inplace=True)\n",
    "symbol_columns = ['TM', 'modifications_ring', 'modifications_chain', 'Conjugate_structure','period','group_id']\n",
    "for column in symbol_columns:\n",
    "    X[column], _ = pd.factorize(X[column])\n",
    "\n",
    "\n",
    "for column in X.keys():\n",
    "    X[column] = (X[column] - X[column].mean()) / X[column].std()\n",
    "\n",
    "    \n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# data_filled = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "# X = stdscale.fit_transform(X)stdscale.fit_transform(X[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算相关系数矩阵，包含了任意特征的相关系数，皮尔逊系数\n",
    "# print('相关系数矩阵为：\\n', X.corr())\n",
    "\n",
    "# 绘制相关性热力图\n",
    "# plt.subplots(figsize=(8, 8))  # 设置画面大小 \n",
    "# plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "# plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号 \n",
    "keys = X.keys()\n",
    "# 绘制热力图\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(X.corr(), cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Pearson Correlation Coefficient Heatmap', fontweight='bold')\n",
    "plt.xlabel('Features', fontweight='bold')\n",
    "plt.ylabel('Features', fontweight='bold')\n",
    "plt.xticks(np.arange(len(keys)), keys, rotation=90)\n",
    "plt.yticks(np.arange(len(keys)), keys)\n",
    "plt.show()\n",
    "\n",
    "# plt.title('相关性热力图')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制GBR模型中特征的权重\n",
    "\n",
    "def my_autopct(pct):\n",
    "    return f'{pct:.1f}%' if pct > 5 else ''#   >5 表示显示占比大于5%的\n",
    "\n",
    "result = pd.DataFrame(columns=y.columns)\n",
    "\n",
    "result.insert(0, 'Method', ['SVM', 'Linear Regression', 'Decision Tree Regression', 'Random Forest Regression', 'Gradient Boosting Regression', 'Mean MSE'])\n",
    "for i in range(5):\n",
    "    print(y.columns[i], \"as label\")\n",
    "    data1 = pd.concat([X, y.iloc[:,i]], axis=1)\n",
    "    # 删除含有缺失标签的样本\n",
    "    data_cleaned = data1.dropna(subset=[data1.columns[-1]])\n",
    "\n",
    "    # 分离特征和标签\n",
    "    X_cleaned = data_cleaned.iloc[:, :-1]  # 取前n-1列为特征\n",
    "    y_cleaned = data_cleaned.iloc[:,-1]  # 取最后一列为标签\n",
    "    keys = X_cleaned.keys()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 初始化梯度提升回归模型\n",
    "    gb = GBR(learning_rate = 0.1, n_estimators = 50)\n",
    "    #1{learning_rate = 0.01, n_estimators = 200}\n",
    "    #3{learning_rate = 0.01, n_estimators = 200}\n",
    "    #{learning_rate = 0.1, n_estimators = 50}\n",
    "    \n",
    "    #gb = RandomForestRegressor(max_depth = 20, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 50)\n",
    "    #0{max_depth = 20, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 100}\n",
    "    #2{max_depth = 20, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 50}   \n",
    "    \n",
    "    # 拟合模型\n",
    "    gb.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上做预测\n",
    "    y_pred = gb.predict(X_test)\n",
    "    y_out = gb.predict(X_train)\n",
    "\n",
    "    # 评估模型性能\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(\"Gradient Boosting Regression \\n Mean Squared Error: \", mse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.11, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"MSE: {mse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "    feature_importance = gb.feature_importances_\n",
    "    custom_colors =[(0.12156862745098039, 0.4666666666666667, 0.7058823529411765), (0.6823529411764706, 0.7803921568627451, 0.9098039215686274),\n",
    "     (1.0, 0.4980392156862745, 0.054901960784313725), (1.0, 0.7333333333333333, 0.47058823529411764),\n",
    "      (0.17254901960784313, 0.6274509803921569, 0.17254901960784313), \n",
    "      (0.596078431372549, 0.8745098039215686, 0.5411764705882353), (0.8392156862745098, 0.15294117647058825, 0.1568627450980392), (1.0, 0.596078431372549, 0.5882352941176471),\n",
    "       (0.5803921568627451, 0.403921568627451, 0.7411764705882353), (0.7725490196078432, 0.6901960784313725, 0.8352941176470589), (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),\n",
    "        (0.7686274509803922, 0.611764705882353, 0.5803921568627451), (0.8901960784313725, 0.4666666666666667, 0.7607843137254902), (0.9686274509803922, 0.7137254901960784, 0.8235294117647058),\n",
    "         (0.4980392156862745, 0.4980392156862745, 0.4980392156862745), (0.7803921568627451, 0.7803921568627451, 0.7803921568627451), (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),\n",
    "          (0.8588235294117647, 0.8588235294117647, 0.5529411764705883), (0.09019607843137255, 0.7450980392156863, 0.8117647058823529), (0.6196078431372549, 0.8549019607843137, 0.8980392156862745)\n",
    "          ,'orangered', 'red', 'mediumslateblue']\n",
    "    #custom_colors = ['darkorchid', 'yellow', 'orangered', 'red', 'cyan', 'lawngreen', 'lightgray', 'pink', 'slateblue',  \n",
    "    #                'gold', 'lightcoral', 'azure', 'tomato', 'palegreen', 'brown', 'mediumslateblue', 'cornflowerblue', \n",
    "    #                'dodgerblue', 'darksalmon', 'deepskyblue', 'violet', 'darkblue', 'peachpuff', 'powderblue', 'maroon', 'hotpink']\n",
    "    #custom_colors = sns.color_palette('tab20')  # Replace 'muted' with your chosen palette\n",
    "    #print(custom_colors)\n",
    "    # 绘制饼状图\n",
    "    plt.figure(figsize=(23, 23))\n",
    "    patches, texts, autotexts = plt.pie(feature_importance, autopct=my_autopct, startangle=140, textprops={'fontsize': 50}, pctdistance=0.7,colors=custom_colors)\n",
    "    # 画饼状图textprops={'fontsize': 35}字体大小；pctdistance=0.7饼状图中的百分数离圆心的距离\n",
    "    plt.legend(patches, [f'{name} ({value*100:.1f}%)' for name, value in zip(keys, feature_importance)],frameon=False, loc=\"center left\", bbox_to_anchor=(1, 0.5), prop={'size':35})\n",
    "    # 标签prop={'size':35}字体大小；\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"Feature Importance Pie Chart of \"+ y.columns[i], fontsize=50)\n",
    "    fn = \"Feature Importance Pie Chart of \"+ y.columns[i] + \".png\"\n",
    "#     plt.savefig(fn, dpi=300) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainSVM(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    svr = SVR(kernel='rbf', C=100, gamma=0.01 )    # linear sigmoid rbf poly\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    y_out = svr.predict(X_train)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(\"SVM \\n Mean Squared Error: \", mse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.11, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"RMSE: {test_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainLinReg(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)\n",
    "\n",
    "    # 初始化线性回归模型\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    # 拟合模型\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上做预测\n",
    "    y_pred = lr.predict(X_test)\n",
    "    y_out = lr.predict(X_train)\n",
    "\n",
    "    # 评估模型性能\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(\"Linear Regression \\n Mean Squared Error: \", mse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.11, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"RMSE: {test_rmse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainDeciTree(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 初始化决策树回归模型\n",
    "    dt = DecisionTreeRegressor()\n",
    "\n",
    "    # 拟合模型\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上做预测\n",
    "    y_pred = dt.predict(X_test)\n",
    "    y_out = dt.predict(X_train)\n",
    "\n",
    "    # 评估模型性能\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(\"Decision Tree Regression \\n Mean Squared Error: \", mse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.11, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"MSE: {mse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainRandForest(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 初始化随机森林回归模型\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # 拟合模型\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上做预测\n",
    "    y_pred = rf.predict(X_test)\n",
    "    y_out = rf.predict(X_train)\n",
    "\n",
    "    # 评估模型性能\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(\"Random Forest Regression \\n Mean Squared Error: \", mse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.11, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"MSE: {mse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainBoost(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "    # 初始化梯度提升回归模型\n",
    "    # n_estimators=100, max_depth=3\n",
    "    gb = GBR(n_estimators=15, max_depth=3, learning_rate=0.2)\n",
    "\n",
    "    # 拟合模型\n",
    "    gb.fit(X_train, y_train)\n",
    "\n",
    "    # 在测试集上做预测\n",
    "    y_pred = gb.predict(X_test)\n",
    "    y_out = gb.predict(X_train)\n",
    "\n",
    "    # 评估模型性能\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    trainR2 = r2_score(y_train, y_out)\n",
    "    testR2 = r2_score(y_test, y_pred)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    print(\"Gradient Boosting Regression \\n Mean Squared Error: \", mse, \"train R2: \", trainR2, \"test R2: \", testR2)\n",
    "    x = np.append(y_train, y_test)\n",
    "    ax1.scatter(y_train, y_out, color='turquoise', label='Train data',alpha=0.7)\n",
    "    ax1.scatter(y_test, y_pred, color='deeppink', label='Test data',alpha=0.7)\n",
    "    text_props = {'ha': 'right', 'va': 'bottom', 'fontsize': 12}\n",
    "    ax1.text(0.99, 0.11, f\"Training R$^{2}$: {trainR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.06, f\"Test R$^{2}$: {testR2:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.text(0.99, 0.01, f\"MSE: {mse:.2f}\", transform=ax1.transAxes, **text_props)\n",
    "    ax1.legend(loc='upper left',  frameon=False)\n",
    "    #ax1.plot(x, x, color='gray', linewidth=2, linestyle='--')\n",
    "    ax1.plot(ax1.get_xlim(), ax1.get_xlim(), color='gray', linewidth=2, linestyle='--')\n",
    "    plt.xlabel(\"E(DFT) (eV)\", fontweight='bold')\n",
    "    plt.ylabel('E(ML) (eV)', fontweight='bold')\n",
    "    plt.show()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=y.columns)\n",
    "result.insert(0, 'Method', ['SVM', 'Linear Regression', 'Decision Tree Regression', 'Random Forest Regression', 'Gradient Boosting Regression', 'Mean MSE'])\n",
    "for i in range(5):\n",
    "    print(y.columns[i], \"as label\")\n",
    "    data1 = pd.concat([X, y.iloc[:,i]], axis=1)\n",
    "    # 删除含有缺失标签的样本\n",
    "    data_cleaned = data1.dropna(subset=[data1.columns[-1]])\n",
    "\n",
    "    # 分离特征和标签\n",
    "    X_cleaned = data_cleaned.iloc[:, :-1]  # 取前n-1列为特征\n",
    "    y_cleaned = data_cleaned.iloc[:,-1]  # 取最后一列为标签\n",
    "\n",
    "    mseSVM = TrainSVM(X_cleaned, y_cleaned)\n",
    "    result.iloc[0, i+1] = mseSVM\n",
    "    mseLinReg = TrainLinReg(X_cleaned, y_cleaned)\n",
    "    result.iloc[1, i+1] = mseLinReg\n",
    "    mseDeciTree = TrainDeciTree(X_cleaned, y_cleaned)\n",
    "    result.iloc[2, i+1] = mseDeciTree\n",
    "    mseRandForest = TrainRandForest(X_cleaned, y_cleaned)\n",
    "    result.iloc[3, i+1] = mseRandForest\n",
    "    mseBoost = TrainBoost(X_cleaned, y_cleaned)\n",
    "    result.iloc[4, i+1] = mseBoost\n",
    "#     mseBP = TrainBP(X_cleaned, y_cleaned)\n",
    "    mseAvg = (mseSVM + mseLinReg + mseDeciTree + mseRandForest + mseBoost) / 5\n",
    "    result.iloc[5, i+1] = mseAvg\n",
    "    print(\"Average MSE: \", mseAvg)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    \n",
    "result.to_csv('res.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8e891ee1b9d2b2f19c0e5aa6fb43259d9f1a8df60b951ce34e42ceabf6c3239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
